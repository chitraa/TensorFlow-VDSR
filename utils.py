import cv2
import numpy as np
import os 
import h5py



# Get the Image
def imread(path):
    img = cv2.imread(path, 0) #grayscale
    img = img/255. #normalize so that values lie between 0 and 1
    img = np.expand_dims(img, axis=2) #(48, 48) -> (48, 48, 1)
    return img

def imsave(image, path, config):
    #checkimage(image)
    # Check the check dir, if not, create one
    if not os.path.isdir(os.path.join(os.getcwd(),config.result_dir)):
        os.makedirs(os.path.join(os.getcwd(),config.result_dir))

    # NOTE: because normial, we need mutlify 255 back    
    cv2.imwrite(os.path.join(os.getcwd(),path),image * 255.)

def checkimage(image):
    cv2.imshow("test",image)
    cv2.waitKey(0)


def checkpoint_dir(config):
    if config.is_train:
        return os.path.join('./{}'.format(config.checkpoint_dir), "train.h5")
    else:
        return os.path.join('./{}'.format(config.checkpoint_dir), "test.h5")

def load_data(config, test_img):
    input_images_filepaths, label_images_filepaths = load_data_paths(config, test_img)
    for times in range(len(input_images_filepaths)):
        make_data_hf(imread(input_images_filepaths[times]), imread(label_images_filepaths[times]), config, times)

def load_data_paths(config, test_img):
    #TODO test_img if not "", set as test path
    #config.is_train = True
    input_images_filepaths = [] #noisy images
    label_images_filepaths = [] #ground truth
    test_result_images_filepaths = [] #image paths to be written at for images generated by NN 
    if config.is_train:
        dataset_type = "train"
    else:
        dataset_type = "test"
     
    pwd_parent = os.path.abspath('..')
    data_file_dir = pwd_parent + "/point-networks/mesh_denoising/mesh_denoising_data/" 
    data_type_dirs = ["Kinect_Fusion", "Kinect_v1"]#, "Kinect_v2"], "Synthetic"]
    
    for data_type_dir in data_type_dirs:
        image_files_dir = os.path.join(data_file_dir, data_type_dir, dataset_type)
        image_files_dir = os.path.join(image_files_dir, "image_patches")
        image_patches_filenames = [f for f in os.listdir(os.path.join(image_files_dir, "noisy")) if f.endswith('.jpg')]
        for patch_name in image_patches_filenames:
            input_images_filepaths.append(os.path.join(image_files_dir, "noisy", patch_name))
            label_images_filepaths.append(os.path.join(image_files_dir, "original", patch_name))
            if( not config.is_train):
                test_result_images_filepaths(os.path.join(image_files_dir, "result", patch_name))

    return input_images_filepaths, label_images_filepaths, 

def read_data(path):
    """
        Read h5 format data file

        Args:
            path: file path of desired file
            data: '.h5' file format that contains  input values
            label: '.h5' file format that contains label values 
    """
    with h5py.File(path, 'r') as hf:
        input_ = np.array(hf.get('input'))
        label_ = np.array(hf.get('label'))
        return input_, label_
    
    
#https://github.com/hengchuan/RDN-TensorFlow/blob/master/utils.py
def make_data_hf(input_, label_, config, times):
    """
    input_ : 1 image, noisy
    label_ : 1 image, ground truth
    """
    if not os.path.isdir(os.path.join(os.getcwd(),config.checkpoint_dir)):
        os.makedirs(os.path.join(os.getcwd(),config.checkpoint_dir))

    if config.is_train:
        savepath = os.path.join(os.path.join(os.getcwd(), config.checkpoint_dir), 'train.h5')
    else:
        savepath = os.path.join(os.path.join(os.getcwd(), config.checkpoint_dir), 'test.h5')

    if times == 0:
        if os.path.exists(savepath):
            print("\n%s have existed!\n" % (savepath))
            return False
        else:
            hf = h5py.File(savepath, 'w')

            input_h5 = hf.create_dataset("input", (1, config.image_size, config.image_size, config.c_dim), 
                                        maxshape=(None, config.image_size, config.image_size, config.c_dim), 
                                        chunks=(1, config.image_size, config.image_size, config.c_dim), dtype='float32')
            label_h5 = hf.create_dataset("label", (1, config.image_size, config.image_size, config.c_dim), 
                                        maxshape=(None, config.image_size, config.image_size, config.c_dim), 
                                        chunks=(1, config.image_size, config.image_size, config.c_dim),dtype='float32')
    else:
        hf = h5py.File(savepath, 'a')
        input_h5 = hf["input"]
        label_h5 = hf["label"]

    input_h5.resize([times + 1, config.image_size, config.image_size, config.c_dim])
    input_h5[times : times+1] = input_
    label_h5.resize([times + 1, config.image_size, config.image_size, config.c_dim])
    label_h5[times : times+1] = label_

    hf.close()
    return True

def make_data_hf_old(input_, label_, config):
    """
        Make input data as h5 file format
        Depending on "is_train" (flag value), savepath would be change.
    """
    # Check the check dir, if not, create one
    if not os.path.isdir(os.path.join(os.getcwd(),config.checkpoint_dir)):
        os.makedirs(os.path.join(os.getcwd(),config.checkpoint_dir))

    if config.is_train:
        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/train.h5')
    else:
        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/test.h5')

    with h5py.File(savepath, 'w') as hf:
        #checkimage(input_[1])
        hf.create_dataset('input', data=input_)
        hf.create_dataset('label', data=label_)

#def merge(images, size, c_dim):
#    """
#        images is the sub image set, merge it
#    """
#    h, w = images.shape[1], images.shape[2]
#    
#    img = np.zeros((h*size[0], w*size[1], c_dim))
#    for idx, image in enumerate(images):
#        i = idx % size[1]
#        j = idx // size[1]
#        img[j * h : j * h + h,i * w : i * w + w, :] = image
#        #cv2.imshow("srimg",img)
#        #cv2.waitKey(0)
#        
#    return img

def input_setup(config):
    """
        Read image files and save them in a h5 file format
    """
    # Load data path, if is_train False, get test data
    load_data(config, config.test_img)


    return 0,0

